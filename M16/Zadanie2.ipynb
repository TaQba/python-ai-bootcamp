{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "825fa3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulacja danymi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# wizualizacja\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773dd744",
   "metadata": {},
   "source": [
    "# Regresja  z PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af31c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_raw = pd.read_csv('daily-bike-share.csv')\n",
    "bike_data_raw['dteday'] = pd.to_datetime(bike_data_raw['dteday'])\n",
    "\n",
    "bike_data = bike_data_raw.copy()\n",
    "bike_data.drop(['instant', 'dteday', 'yr'], axis=1, inplace=True)\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit']\n",
    "target = 'rentals'\n",
    "\n",
    "X = bike_data[['temp']].copy()\n",
    "y = bike_data[target].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "def train_and_check(Xtrain, Xtest, ytrain, ytest):\n",
    "    classifier = LinearRegression()\n",
    "    start = datetime.datetime.now()\n",
    "    classifier.fit(Xtrain, ytrain)\n",
    "    end = datetime.datetime.now()\n",
    "    time = (end - start).microseconds\n",
    "    evaluation = np.round(classifier.score(Xtest, ytest), 4)\n",
    "    return evaluation, time\n",
    "\n",
    "results = PrettyTable(['Model',\n",
    "                       'Dokładność',\n",
    "                       'Czas trenowania (microseconds)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af8dcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaler)\n",
    "X_test_pca = pca.transform(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ad08615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------------------------+\n",
      "|       Model       | Dokładność | Czas trenowania (microseconds) |\n",
      "+-------------------+------------+--------------------------------+\n",
      "| Nieskalowane dane |   0.1941   |              4423              |\n",
      "|   Skalowane dane  |   0.1941   |              825               |\n",
      "|        4 PC       |   0.1941   |              772               |\n",
      "|        3 PC       |   0.1941   |              757               |\n",
      "|        2 PC       |   0.1941   |              977               |\n",
      "|        1 PC       |   0.1941   |              755               |\n",
      "+-------------------+------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable(['Model',\n",
    "                       'Dokładność',\n",
    "                       'Czas trenowania (microseconds)'])\n",
    "\n",
    "# Trenowanie modelu na nieprzetworzonym zbiorze\n",
    "not_scaled_data = train_and_check(X_train, X_test, y_train, y_test)\n",
    "results.add_row(['Nieskalowane dane', not_scaled_data[0], not_scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na przetworzonym zbiorze\n",
    "scaled_data = train_and_check(X_train_scaler, X_test_scaler, y_train, y_test)\n",
    "results.add_row(['Skalowane dane', scaled_data[0], scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(X_train_pca, X_test_pca, y_train, y_test)\n",
    "results.add_row(['4 PC', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na trzech Głównych Składowych\n",
    "PC3_data = train_and_check(X_train_pca[:, :3], X_test_pca[:, :3], y_train, y_test)\n",
    "results.add_row(['3 PC', PC3_data[0], PC3_data[1]])\n",
    "\n",
    "# Trenowanie modelu na dwóch Głównych Składowych\n",
    "PC2_data = train_and_check(X_train_pca[:, :2], X_test_pca[:, :2], y_train, y_test)\n",
    "results.add_row(['2 PC', PC2_data[0], PC2_data[1]])\n",
    "\n",
    "# Trenowanie modelu na jednej Głównej Składowej\n",
    "PC1_data = train_and_check(X_train_pca[:, :1], X_test_pca[:, :1],  y_train, y_test)\n",
    "results.add_row(['1 PC', PC1_data[0], PC1_data[1]])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68662e8",
   "metadata": {},
   "source": [
    "# Klasyfikacja  z PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1bae13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "target = 'Diabetic'\n",
    "X, y = diabetes[features], diabetes[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['Pregnancies', 'Age']], y, test_size=0.30, random_state=0, stratify=y)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_and_check(Xtrain, Xtest, ytrain, ytest):\n",
    "    classifier = KNeighborsClassifier(n_neighbors= int(Xtrain.shape[0]*0.001))\n",
    "    start = datetime.datetime.now()\n",
    "    classifier.fit(Xtrain, ytrain)\n",
    "    end = datetime.datetime.now()\n",
    "    time = (end - start).microseconds\n",
    "    evaluation = np.round(classifier.score(Xtest, ytest), 4)\n",
    "    return evaluation, time\n",
    "\n",
    "results = PrettyTable(['Model',\n",
    "                       'Dokładność',\n",
    "                       'Czas trenowania (microseconds)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f0d8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaler)\n",
    "X_test_pca = pca.transform(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c5ab16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------------------------------+\n",
      "|       Model       | Dokładność | Czas trenowania (microseconds) |\n",
      "+-------------------+------------+--------------------------------+\n",
      "| Nieskalowane dane |   0.8778   |             12011              |\n",
      "|   Skalowane dane  |   0.8758   |              2047              |\n",
      "|        4 PC       |   0.8729   |              1826              |\n",
      "|        3 PC       |   0.8729   |              1856              |\n",
      "|        2 PC       |   0.8729   |              1845              |\n",
      "|        1 PC       |   0.8582   |              1472              |\n",
      "+-------------------+------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "results = PrettyTable(['Model',\n",
    "                       'Dokładność',\n",
    "                       'Czas trenowania (microseconds)'])\n",
    "\n",
    "# Trenowanie modelu na nieprzetworzonym zbiorze\n",
    "not_scaled_data = train_and_check(X_train, X_test, y_train, y_test)\n",
    "results.add_row(['Nieskalowane dane', not_scaled_data[0], not_scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na przetworzonym zbiorze\n",
    "scaled_data = train_and_check(X_train_scaler, X_test_scaler, y_train, y_test)\n",
    "results.add_row(['Skalowane dane', scaled_data[0], scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(X_train_pca, X_test_pca, y_train, y_test)\n",
    "results.add_row(['4 PC', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na trzech Głównych Składowych\n",
    "PC3_data = train_and_check(X_train_pca[:, :3], X_test_pca[:, :3], y_train, y_test)\n",
    "results.add_row(['3 PC', PC3_data[0], PC3_data[1]])\n",
    "\n",
    "# Trenowanie modelu na dwóch Głównych Składowych\n",
    "PC2_data = train_and_check(X_train_pca[:, :2], X_test_pca[:, :2], y_train, y_test)\n",
    "results.add_row(['2 PC', PC2_data[0], PC2_data[1]])\n",
    "\n",
    "# Trenowanie modelu na jednej Głównej Składowej\n",
    "PC1_data = train_and_check(X_train_pca[:, :1], X_test_pca[:, :1],  y_train, y_test)\n",
    "results.add_row(['1 PC', PC1_data[0], PC1_data[1]])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c29f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
